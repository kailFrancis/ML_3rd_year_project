{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"01d1415167e644619ad712a89f06acd2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1684183983753,"source_hash":"49024fbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["hello\n"]}],"source":["print('hello')"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"0a6e53007d7847cfa041b4e1bf09a303","deepnote_cell_height":142,"deepnote_cell_type":"markdown"},"source":["# IIA project SF3: Machine Learning\n","\n","Easter 2023<br>\n","Project Leader: Gabor Csanyi (gc121)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"9bb36a3ae0554d97b51a750d7bdd48d7","deepnote_cell_height":1201,"deepnote_cell_type":"markdown","owner_user_id":"61bef1ae-8549-4162-b989-01c78a3f94df"},"source":["## Important dates\n","\n","Project start: __Friday May 12 2023 11:00am GMT+1 (UK summer time)__ \n","\n","Interim report deadline: __Friday 19 May 2023, 4pm__ (electronic submission via Moodle)\n","<br>\n","(Interim report should contain report on tasks up to and including the linear modelling of the dynamics)\n","\n","Final project report deadline: __Friday 9 June 2023,  4pm__ (electronic submission via Moodle)\n","\n","\n","## Project notes\n","\n","- You should spend about 20 hours a week on the project, basically half of your time.\n","- Project is to be carried out here on Deepnote or on your own computer. You can download this notebook and use it with a normal Jupyter server, or duplicate it here in your Deepnote account. If you do the latter, you can share and show your work easily. The computational resources on Deepnote are limited, so you may find it more convenient to run the programs on your own computer in the later parts of the project. When you need to ask a question about a specific piece of code, you can still use the Deepnote system to share a notebook. \n","- Make your own schedule. Help is available from the project leader during scheduled sessions: 10:00am - 11:00am (GMT+1) every weekday on in LR5. None of the subsequent sessions are compulsory, but you are strongly encouraged to seek verbal feedback after your interim report - there will be a special sessions for this on Monday and Tuesday, May 22-23 also in LR5. \n","- Project carries 80 marks overall:\n","  - 20 marks for interim report\n","  - 60 marks for final report \n","- Project report\n","  - Should be clearly broken down by _Tasks_ (see below), any notes you wish to make in how you structured and carried out the tasks, and most importantly your __results__ in the form of completely labelled graphs, and __accompanying conclusions__ you draw from your results. \n","  - Should be about than 14-18 pages (Interim report about 4-6 pages) when converted to a PDF (excluding appendices such as attached code, but _including_ figures). The final report can be an extension of the interim report, but make sure you take into account the feedback you receive for your interim report.  \n","  - When deciding what to include in your report, how to organise it and what to emphasize, please prioritise communicating understanding over formalities - I would like give you marks for doing the right thing and showing that you did it and understand it. If I have to wade through pages of undigested data and graphs shown just because it was there, I will feel less generous. The length requirements are only guidelines. \n","  - __All code__ that you used during to project must be attached as an appendix to your reports. If you modified the `CartPole.py` file, include it. \n","  - A jupyter or Deepnote notebook are acceptable as a report, as long as it is \"clean\" (its main section includes text and figures) and reads like a report, and can be converted to a PDF for the moodle upload. \n","  - Incude [cover sheets](http://teaching.eng.cam.ac.uk/node/4171) provided by the Teaching Office\n","\n","## Approximate Schedule\n","\n","- Week 1: Software tools, simulation of cart-pole system, linear modelling of dynamics\n","  - Interim report (up to linear modelling)\n","- Week 2: Nonlinear modelling of dynamics, linear control\n","- Week 3: Sensitivity analysis\n","- Week 4: Nonlinear control\n","  - Final report"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"bfad30642cfa43b19188ecbe8eeadb86","deepnote_cell_height":70,"deepnote_cell_type":"markdown"},"source":["<IMG src=\"~/work/cartpole.png\" width=500>"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"234f415c587c443796ed465f34e0793f","deepnote_cell_height":118,"deepnote_cell_type":"markdown"},"source":["## Week 1\n","\n","### Dynamical simulation"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"9701abfa2ea94dbb89b440979532a491","deepnote_cell_height":74,"deepnote_cell_type":"markdown"},"source":["Consider the inverted pendulum system (\"cartpole\") drawn above, familiar from the coursework of 3F2, with a freely moving cart and freely rotating pendulum attached to the cart, moving under the action of an external action force and gravity. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"2ece7554e32c49c3922c58eb05450aa9","deepnote_cell_height":172,"deepnote_cell_type":"markdown"},"source":["\n","The equations of motion of the system are \n","\n","$$\n","\\begin{array}{lll}\n","3 \\ddot x \\cos \\theta  + 2 L \\ddot \\theta & = &  3 g \\sin \\theta - 6 \\mu_\\theta \\dot\\theta/mL\\\\\n","(m+M) \\ddot x + \\frac12 m L\\ddot\\theta\\cos\\theta - \\frac12 mL{\\dot\\theta}^2 \\sin\\theta &=& F - \\mu_x \\dot x\n","\\end{array}\n","$$\n","\n","where the stationary points are $\\theta=0$ (unstable) and $\\theta=\\pi$ (stable), and $F$ is the external _action_ (force) on the cart, $\\mu_x$ and $\\mu_\\theta$ \n","are the friction coefficients of the cart and the pole, respectively. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"43c472ea37ba4a14b291ca16e3402249","deepnote_cell_height":118,"deepnote_cell_type":"markdown"},"source":["The state of the system is described by the following variables: position and velocity\n","of the cart $x, \\dot x$, angle and angular velocity of the pole $\\theta, \\dot\\theta$, with\n","the angle being periodic on $[-\\pi,\\pi]$. The center position of the cart corresponds to $x=0$,\n","and the pole hanging vertically down corresponds to $\\theta=\\pi$. If you are interested in deriving\n","the equations of motion for yourself, use Lagrange's equation. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"1f9ccb916c42437cb01b02f2eb94bff1","deepnote_cell_height":394,"deepnote_cell_type":"markdown"},"source":["#### Task 1.1\n","\n","Study the code in the `CartPole.py` file, which creates a Python class to describe the system. Note the variables that describe to the state of system, and the `performAction()` function that updates the state variables using the _Euler_ algorithm (it does a small number of steps), using a given force (which is the 'action') on the cart. Passing a zero value for the force corresponds to free dynamics. \n","\n","Write code to simulate a “rollout” (i.e. a run with specified initial condition simulated for a number of time steps) using the `performAction` function in a loop, starting from the stable equilibrium position and some nonzero initial cart velocity or angular velocity, and no applied force. Plot the resulting time evolution of the system variables. Vary the size of the initial velocities to realize different behaviours: simple oscillation around the stable equilibrium, and also the complete rotation of the pendulum. Useful ranges are as follows. Cart velocity: $[-10,10]$, pole angle: $[-\\pi,\\pi]$, pole (angular) velocity: $[-15,15]$.\n","\n","You can plot all variables as a function of time, and also pairs of variables against one another (similar to phase portraits).\n","\n","\n","Note how the angle is used in the dynamics as a continous variable, rather than just in the range $[-\\pi,\\pi]$. There is a `remap_angle` function in the `CartPole` module that you can use to get the angle in the usual range. _This will be an important consideration later on when we develop models of the dynamics._\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"11b77285d4704ba88382fd74c7effee7","deepnote_cell_height":188,"deepnote_cell_type":"markdown"},"source":["### Changes of state\n","\n","You know from 3F2 that a simple linear controller works for this system, as long as you know where the stationary point is, and have access to the equations of motion so that you can linearise them. But in general, we do not know the equations behind the evolution of a physical system, and so we will take a different approach. What do have are _observations_ of the time evolution of the system. So we will use the simulations like the ones you did above to gather data about the system, and develop a _model_ for this time evolution. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"399d4c2828554393821c3bb27bdf230d","deepnote_cell_height":146,"deepnote_cell_type":"markdown"},"source":["\n","We will want to build a _model_ for the time evolution of the system. The model is a function $f(X)$ that takes the current state of the system, and maps it onto a new state, which is its prediction for the state at a later time. Let the state of the system be described by a vector X, given by\n","\n","$$\n","X = [x, \\dot x, \\theta, \\dot \\theta]\n","$$"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"5e29c28870fb4b81a0f1768194d73902","deepnote_cell_height":74,"deepnote_cell_type":"markdown"},"source":["Given the current state $X$, let us call $Y$ the state of the system after a single call to the `PerformAction` function (with 0.0 as the force argument, or no argument, which is equivalent). "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"c3bfa31761dc4b3098d072195fcf12e6","deepnote_cell_height":132,"deepnote_cell_type":"markdown"},"source":["#### Task 1.2\n","\n","To investigate and visualise the functional relationship between $X$ and $Y$, initialise the system using a random value for all state variables, and then scan through one of the state variables in a suitable range (don't forget to reset all the state variables after each call to `PerformAction`), and plot $Y$ as a function of your scan. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"1b8a9cca00684f6d89578cedcbc1f936","deepnote_cell_height":278,"deepnote_cell_type":"markdown"},"source":["You will observe that the relationship between $X$ and $Y$ as defined above is nearly linear, which is not surprising because the change in one step is small.\n","\n","We can take account of this and model the _change_ in state vector, rather than taking the new state vector itself as the target of our model. So we define the new target for the modelling as $Y\\equiv X(T)-X(0)$, where $X(t)$ represents the time evolution of the state under the dynamics, and T corresponds to a single call to `PerformAction`. Note that in principle we could model changes corresponding arbitrary time shifts, rather than a single call to `PerformAction`, but the longer the time shift, the more complex the model would have to be. \n","\n","Explore this new functional relationship again (i) using scans of single variables, and (ii) contour plots where you take slices of the data in two of the variables while you keep the other two variables fixed (the `tricontourf` function of `matplotlib` is very useful). One of the variables has no effect on the next step - which one? "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"8efce30996524cedb6e92c181ab72ad6","deepnote_cell_height":62,"deepnote_cell_type":"markdown","tags":[]},"source":["### Linear model"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"8f592e22c185470588f9a502863f2e57","deepnote_cell_height":124,"deepnote_cell_type":"markdown"},"source":["\n","The simplest model is a linear one, where the target $Y$ is assumed to be linear function of the current state $X$,\n","$$\n","f(X) = {\\bf C} X\n","$$\n","\n","where ${\\bf C}$ is a $4\\times 4$ matrix of coefficients. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"7d5378a4456c4ce18bbc811c711be1b4","deepnote_cell_height":132,"deepnote_cell_type":"markdown"},"source":["#### Task 1.3\n","\n","By initialising the simulator in a completely random state (using suitable ranges) and running it for _one_ step, gather\n","data in the form of pairs of state vectors (X, Y), where X represents a state of the system at step $n$, so $X\\equiv X(n)$\n","and Y represent the change in state after a single call to `performAction` (with zero force), so $Y\\equiv X(n+1)-X(n)$. \n","Start with 500 data points. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"6935e7f4fc184fdc95a9b1970a18c811","deepnote_cell_height":184,"deepnote_cell_type":"markdown"},"source":["Using your data set, do linear regression to find the optimal coefficient matrix. Test your predictions against the data. One way to plot the results is to put the input state variable on the horizontal axis and on the vertical axis put the predicted state variable (i.e. what should be the \"next step\") and the real next step. Another way is to put the target data (i.e. the real \"next step\") on the horizontal axis and the predicted \"next step\" on the vertical axis. In this latter plot, a perfect prediction would correspond to a perfect straight line. You should also repeat the \"scans\" from the previous task, and plot simultaneously the real change in state with your predicted change in state as a function of your scan. Which variables are predicted well by the linear model and which ones are not? Why ? "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"1ae2c4148d5e445586a5dbdbae223a44","deepnote_cell_type":"markdown"},"source":["#### Task 1.4\n","\n","The true test of the model is not how it matches with the gathered data it was fit to, but whether it can predict the time evolution of the physical system. Iterate the model to predict the time evolution of the system, and compare using various initial conditions how accurate the predictions are with respect to the true dynamics started from the same initial conditions. (Note that the model is being used deterministically, with no noise added)\n","\n","Since your models above predict the _change_ in the state variable, the iterated time evolution is\n","$$\n","X_{n+1} \\leftarrow X_n + f(X_n)\n","$$\n","\n","Plot the true time evolution of the system as well as that of your fitted models for many cycles, and for different initial conditions, including ones where the pole makes a full circle. \n","\n","_Angle range_ If you leave the angle without remapping, your solution with the iterated model will diverge. Why is that? Ensure that you remap the angle during the above iterations. (Note how remapping is not needed in the true dynamics, since that is nonlinear, and the angle only appears inside trigonometric functions that are periodic anyway)."]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"f8350034486a4dac9ad0228d848580da","deepnote_cell_type":"markdown"},"source":["## Week 2\n","\n","### Nonlinear model\n","As you observed above, the linear model is not particularly good. In order to do better, we need nonlinear modelling. Next you are going to do build a nonlinear model using a linear regression with nonlinear basis functions. Given a data set of (X,Y) pairs, the model function is given by\n","\n","$$\n","f(X) = \\sum_i \\alpha_i K(X, X_i)\n","$$\n","\n","where the sum runs over the basis functions, $\\alpha_i$ are the corresponding coefficients, and $K$ is a _kernel function_ that is used to define the nonlinear basis. The kernel function takes two arguments, the first one $X$ is the state vector where you evaluate the basis function, and the second argument, $X_i$ is another state vector which we use to place the basis function somewhere in the state space. To make the basis functions relevant, we take the set of locations $\\{X_i\\}$ to be a subset of the gathered data points.  "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"b1eaf7a2c98b4e728a2ad90f5b40ee10","deepnote_cell_type":"markdown","tags":[]},"source":["If you place a basis functions on every location at which you have data, the functional form above is equivalent to \n","the mean of a _Gaussian process_ with covariance given by the kernel _K_. This view of the regression problem is particularly helpful \n","if the data is stochastic, i.e. it has some noise component which we can model. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"2835d5ee08d44b70aba187a6441ec493","deepnote_cell_type":"markdown"},"source":["For the present problem, let us use a Gaussian kernel function,\n","\n","$$\n","K(X,X') = e^{-\\sum_j \\frac{\\left(X^{(j)}-X'^{(j)}\\right)^2}{2\\sigma_j^2}}\n","$$\n","\n","Here $X^{(j)}$ refers to the $j$th component of the state vector. There is one caveat for using this kernel function in our\n","current situation: one of our state vector components, $\\theta$ is periodic. It helps quite a bit if we introduce this\n","periodicity in our kernel function, and we can do that by using $\\sin^2\\left( (\\theta - \\theta')/2 \\right)$ in place\n","of $\\left(\\theta -\\theta' \\right)^2$ in the part of the kernel function that corresponds to the angle variable. The parameters\n","$\\sigma_j$ are _length scale_ hyperparameters of the model, and need to be known, guessed or fitted. \n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"11e9f1cb3ad24049bd89e9218d9ebf7d","deepnote_cell_type":"markdown","tags":[]},"source":["If we have $N$ data locations (each is an (X,Y) pair but remember that here X is a vector and Y is a scalar), substituting this data into\n","the model functional form yields the following linear system\n","\n","$$\n","K_{NN} \\alpha_N = Y_N\n","$$\n","\n","where the subscript $N$ was used to emphasize the size of the array rather than an index. The unknown coefficients are collected\n","into the vector $\\alpha_N$, the elements of the matrix are given by the kernel function, \n","\n","$$\n","[K_{NN}]_{i,i'} = K(X_i,X_{i'})\n","$$\n","\n","and $Y_N$ is a vector of the target function values. With Gaussian basis functions, the condition number of the matrix is enormous, and a direct solution of the above linear system would be\n","rather unstable. One way to get around this is to _regularise_ the linear system. Tikhonov regularisation is to modify it to \n","\n","$$\n","(K_{NN} + \\lambda I) \\alpha_N = Y_N\n","$$\n","with solution\n","$$\n","\\alpha_N = [K_{NN} + \\lambda I]^{-1} Y_N\n","$$\n","\n","where $\\lambda$ is a parameter. The smaller the values of $\\lambda$, the closer is the fit to the data, but the more unstable\n","the linear system. Interestingly, this is also exactly the form of the (mean) solution in the Gaussian process regression problem of\n","inference in the presence of noisy input data, with the identification that $\\lambda$ is the variance of the data noise. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"d46703201a7b44e28fbda509ba5ed880","deepnote_cell_type":"markdown"},"source":["Suppose we collected $N$ pairs of $(X,Y)$ data pairs, and we choose a subset $M$ of the $X$ locations to serve as basis function centres.\n","The linear system is then not square:\n","$$\n","K_{NM} \\alpha_M = Y_N\n","$$\n","where again the subscripts indicate dimensions, $K_{MN}$ is an $M \\times N$ matrix with elements corresponding to the $M$ basis locations\n","and all the $N$ data point locations. We have fewer unknown coefficients than data points, so the problem is over-determined. \n","The least squares solution would be\n","$$\n","\\alpha_M = [K_{MN} K_{NM}]^{-1} K_{MN} Y_N\n","$$\n","i.e. using the pseudoinverse rather than the inverse. The matrix in square brackets will in general be uninvertible or very badly \n","conditioned, so again we need to regularise. Interestingly, rather just adding a multiple of the identity matrix like in the\n","square case, we can look to Gaussian process inference for a better idea. It turns out that a _sparse Gaussian process_ precisely\n","corresponds to this case. There, the model is written as a conditional probability not on the original $N$ data values directly, but on the\n","unknown function values at the $M$ data locations that are chosen for the basis function centers. The vector of linear coefficients of\n","the fitted model are then given by \n","\n","$$\n","\\alpha^{(j)}_M = \\left(K_{MN}K_{NM} + \\lambda K_{MM} \\right)^{-1} K_{MN}  Y_N^{(j)}\n","$$\n","\n","where $K_{MM}$ is an $M \\times M$ matrix with elements that are given by the kernel function evaluated between the locations\n","selected as basis locations. The interpretation of this is that the least squares system is Tikhonov regularised but the regulariser\n","is evaluated in the kernel-norm, rather than the Euclidean norm. \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"b9e104702db14ca0a03f8c6c61b2dacb","deepnote_cell_type":"markdown","tags":[]},"source":["To apply all the above to the cartpole system, we have to create four separate models for the four components of\n","the state vector, these are indexed by $j$. In the absence of data noise to guide the selection of $\\lambda$, you need to experiment\n","with different values (e.g. between 1E-6 and 1E-1, on a log scale). You will also need to select the length scale parameters $\\sigma_j$ for each state variable. A good start is the standard deviation\n","of the state variable in your dataset. Note that in the Gaussian process inference view of this problem, these hyperparameters \n","would be optimised by minimising the log-likelihood, feel free to research this and experiment with it if you have time. \n","\n","**Note: You should never use the `np.linalg.inv` function to invert the matrix when solving a linear system, because that can be\n","numerically unstable for such ill-conditioned matrices, but instead use `np.linalg.lstsq`, which solves equations of the\n","form $Ax=b$ directly in a least-squares sense.**"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"ee47889a78664e3e8e6fb17389ee3c7e","deepnote_cell_type":"markdown"},"source":["#### Task 2.1\n","\n","Fit a model of the system using the data you gathered earlier. Your target function could be either again the change in\n","state after one step as before, or the _error of your linear model_ in the change in state. Verify using scatterplots that\n","the nonlinear model indeed fits the data. Study the convergence of the model (i.e. the systematic reduction in error) as a\n","function of increasing data amount, and the increasing number of basis functions (e.g. start with $M=10$ and increase by\n","factors of 2, select the data locations for the basis randomly from the data). Also plot 2D slices of your target function\n","and the fit, as well as do roll-outs to see how closely the iterated model matches the real dynamics for a wide range of\n","sensible initial conditions. How long does your model show reasonable agreement with the real dynamics? Quantify this in units of time\n","and also in the number of oscillation cycles. How does this correlate with the pointwise accuracy you measure on random test data? "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"02da8df89b3b42379d50f8e01e65df64","deepnote_cell_type":"markdown"},"source":["An alternative to random data locations is to use _quasirandom sequences_, these provide a set of locations in an arbitrary dimensional unit cube that are \"nicely\" spaced out for sampling, better than random draws. You can use the `sobol_seq` module to generate such locations (read the on-line example, but each new location is obtained with a call to the `vec, seed = sobol_seq.i4_sobol(4, seed)` function for 4 dimensions, with the seed provided by the previous call)"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"8b95db46975c47638dba00b314629ce3","deepnote_cell_type":"markdown"},"source":["## Control"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"f9c731760100441ead083c1e61bfb7e0","deepnote_cell_type":"markdown"},"source":["Having developed a good model for the dynamics, now it is time to control the system. In this exercise we will create a controller\n","to achieve a desired state by parametrising the actions of the controller, and optimising those parameters through evaluation of\n","the performance. This is called _reinforcement learning_ in general. Using the interaction of the controller with the system\n","to improve it is \"direct policy search\". There are many other, more sophisticated strategies.  \n","\n","When you call the `performAction` routine, it takes a signed scalar which is interpreted as an external force on the cart. The value is passed through the `tanh` function \n","before being interpreted as a force, this prevents the application of excessively large forces (the transformation is controlled\n","by the `max_force` variable inside the `CartPole` class.) The first thing you will need do is to modify your models (both the linear and nonlinear) to take account of this new state \n","variable (i.e. your system now has 5 inputs, including the force F, and 4 outputs after a call to `performAction`). "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"2a1bd74b23c24766b624127e2dd8902f","deepnote_cell_type":"markdown"},"source":["#### Task 2.2\n","Change your code so that the state vector now includes the action taken. Collect new data, again using random initial conditions or quasi-random sequences and one step, but this time include the action. Verify using scatter-plots, 1D and 2D scans and roll-outs that your models can predict the change in the state variables.  "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"7231f4b5d55746529e84c5c498bf70ff","deepnote_cell_type":"markdown"},"source":["### Policies\n","\n","A _policy_ is a function $p(X)$ that defines what the action should be given the other state variables. The  goal is \n","to find a policy function that when enacted, gives rise to the desired behaviour, in this case the pole being balanced around \n","its unstable equilibrium position. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"0cd4c33442d94146b57fb2047b1cf105","deepnote_cell_type":"markdown"},"source":["### Objective\n","\n","In order to optimize a policy, we need to define, mathematically, what we want to achieve. That is captured in an _objective function_ (also called\n","_loss function_), a measure of how close we are to the desired behaviour. In the present case, we want the pole to be upright,\n","so we could use the _loss function_\n","\n","$$\n","l(X) = -\\cos\\theta\n","$$\n","\n","But it is better, and more general, to define a _target state_, $X_0$, which we want the system to achieve, and use a loss\n","function that increases when the distance of the state from the target is larger. The following loss function achieves this, \n","\n","$$\n","l(X) = 1- e^{-|X-X_0|^2/2\\sigma_l^2}\n","$$\n","where $\\sigma_l$ is a scaling factor (you could introduce a separate one for each component of the state variable). The target\n","state for the cartpole system is $X_0 = [0,0,0,0]$. The advantage\n","of this form is that for large departures from the target, the loss is independent of the state. This expresses the notion\n","that if the pole is far away from being upright and stationary, we do not much care what it is doing. The above loss functions\n","are for a given state. We wish to keep the pole upright continuously, so the total loss of a trajectory should be a time\n","integral (sum, in practice) of the pointwise loss of the state over some interval,\n","\n","$$\n","L = \\sum_{i=1}^N l(X_i)\n","$$\n","\n","The `CartPole` class contains a function to evaluate the above pointwise loss $l(X)$. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"561ec5b43ae74dc6b3b92e0dc0f38ff6","deepnote_cell_type":"markdown","tags":[]},"source":["### Linear control"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"28521ee03c92476db4e1d8361069e18d","deepnote_cell_type":"markdown"},"source":["We start with defining a linear policy, \n","\n","$$\n","p(X) = \\bf{p} \\cdot X\n","$$\n","\n","with unknown coefficent vector ${\\bf p}$. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"e62028eb8bd34d65a23293a71d8f124e","deepnote_cell_type":"markdown"},"source":["#### Task 2.3\n","\n","Write code to evaluate the loss function for the trajectory of a rollout - use a short time horizon, but enough to capture 1-2 \n","oscillation periods. Before any optimisation, _visualise_ the loss function as you vary some parameters in ${\\bf p}$, using \n","similar 1D and 2D scans that you did for Task 1, i.e. varying just one or two elements of  ${\\bf p}$ and plotting the loss \n","as a function of those elements. \n","\n","Optimise the unknowns in the policy to minimise the loss function. Since you do not have too many variables, you can do this \n","by looking at how the loss changes for small changes in policy variables. Feel free to use off-she-shelf optimizers, e.g. from \n","the `scipy.optimize` package. For low dimensional optimization problems without gradients available, you can use the `Nelder-Mead` method. \n","\n","Do not expect the loss to be a simple function of the policy parameters, or to have only a few minima - it is likely that you need\n","to explore a variety of initial conditions. But there is not just one solution! Explore the loss as a function of the\n","elements of ${\\bf p}$.  Find elements of ${\\bf p}$ that are able to stabilize the pole when started just slightly displaced \n","from the upright unstable position.\n","\n","How close do you have to start? Plot the time evolution of the variables under the policy to demonstrate that the pole is kept upright. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"fa683ae0d7494cf1903b39987ccfee14","deepnote_cell_type":"markdown","tags":[]},"source":["#### Task 2.4\n","\n","In the previous task you used the real dynamics to evaluate a policy. But we have a good _model_ of the dynamics (the nonlinear\n","one from Task 2.1). Try to optimise the policy parameters by testing them on model-rollouts. \n","You need to limit the time horizon (number of steps) to where you think your model is still \n","accurate. (Using models to optimise policy is called _model predictive control_)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"e44fa00a5e8445138352186682783bd6","deepnote_cell_type":"markdown"},"source":["## Week 3: Sensitivity and stability"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"8de4aabdfff84952b7906f53386302de","deepnote_cell_type":"markdown"},"source":["We go back to the beginning of the project, and modify the problem, introducing noise in various forms, and observe its effect. \n","\n","#### Task 3.1\n","\n","Introduce noise in the _observed_ dynamics (but not in the real dynamics of the system). Refit the models (linear and nonlinear), \n","and characterise the degradation in the prediction accuracy. Reoptimise the linear policy, and check its stability, contrasting it with the noise-free case.\n","\n","#### Task 3.2\n","\n","Introduce noise in the actual dynamics of the cartpole system, and repeat the tests of the previous task. \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"e21593ace8f24c319113204bff040d03","deepnote_cell_type":"markdown","tags":[]},"source":["## Week 4: Nonlinear control\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"4f6c5ae86d49450a9dd6d3008af66e62","deepnote_cell_type":"markdown"},"source":["#### Task 4.1\n","\n","Define a _nonlinear_ policy, using a similar construction that we used for modelling the system, but this time we are modelling \n","the `force` action as a function of the system state variables (i.e. the policy). The policy function is thus\n","\n","$$\n","p(X) = \\sum_i w_i e^{-0.5 (X-X_i)^T W (X-X_i)}\n","$$\n","\n","where the locations $X_i$, the weights $w_i$ and the elements of the $4 \\times 4$ symmetrix matrix $W$ are free parameters to be optimised (how do you make sure W is symmetric?). \n","Use between 5-20  basis functions. Optimise the parameters, and try to obtain a policy that can keep the pole upright starting \n","from the stable equilibrium (down) position. Feel free to use special initial conditions that seem reasonable. I suggest you experiment with the noise-free version of the problem.\n","\n","_Note that this task is **hard**, and you may not achieve good control. Do not invest an inordinate amount of effort, but\n","move onto writing your final report if you do not succeed. You do not necessarily need to have found a good nonlinear controller to \n","achieve a good grade in this project_, but I will be looking for good effort and evidence that you tried a variety of ideas. "]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"50ddcff64b914cecbda98fa41e7e592e","deepnote_cell_type":"markdown","tags":[]},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=041cc40d-98d2-497a-9cd8-50c462813389' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"ab4f476fc039434782300f480ee68cee","hide_input":false,"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15"}},"nbformat":4,"nbformat_minor":0}
